{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2. Intelligent Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.)** Suppose that the performance measure is concerned with just the first\n",
    "        $T$ time steps of the environment and ignores everything thereafter.\n",
    "        Show that a rational agent’s action may depend not just on the state of\n",
    "        the environment but also on the time step it has reached.\n",
    "\n",
    "**2.)** Let us examine the rationality of various vacuum-cleaner agent\n",
    "        functions.\n",
    "1.  Show that the simple vacuum-cleaner agent function described in is\n",
    "    indeed rational under the assumptions listed on .\n",
    "\n",
    "2.  Describe a rational agent function for the case in which each\n",
    "    movement costs one point. Does the corresponding agent program\n",
    "    require internal state?\n",
    "\n",
    "3.  Discuss possible agent designs for the cases in which clean squares\n",
    "    can become dirty and the geography of the environment is unknown.\n",
    "    Does it make sense for the agent to learn from its experience in\n",
    "    these cases? If so, what should it learn? If not, why not?\n",
    "\n",
    "**3.)** Write an essay on the relationship between evolution and one or more of\n",
    "        autonomy, intelligence, and learning.\n",
    "\n",
    "**4.)** For each of the following assertions, say whether it is true or false\n",
    "        and support your answer with examples or counterexamples where\n",
    "        appropriate.\n",
    "\n",
    "1.  An agent that senses only partial information about the state cannot\n",
    "    be perfectly rational.\n",
    "\n",
    "2.  There exist task environments in which no pure reflex agent can\n",
    "    behave rationally.\n",
    "\n",
    "3.  There exists a task environment in which every agent is rational.\n",
    "\n",
    "4.  The input to an agent program is the same as the input to the agent\n",
    "    function.\n",
    "\n",
    "5.  Every agent function is implementable by some program/machine\n",
    "    combination.\n",
    "\n",
    "6.  Suppose an agent selects its action uniformly at random from the set\n",
    "    of possible actions. There exists a deterministic task environment\n",
    "    in which this agent is rational.\n",
    "\n",
    "7.  It is possible for a given agent to be perfectly rational in two\n",
    "    distinct task environments.\n",
    "\n",
    "8.  Every agent is rational in an unobservable environment.\n",
    "\n",
    "9.  A perfectly rational poker-playing agent never loses.\n",
    "\n",
    "**5.)** For each of the following activities, give a PEAS description of the\n",
    "        task environment and characterize it in terms of the properties listed\n",
    "        in .\n",
    "\n",
    "-   Playing soccer.\n",
    "\n",
    "-   Exploring the subsurface oceans of Titan.\n",
    "\n",
    "-   Shopping for used AI books on the Internet.\n",
    "\n",
    "-   Playing a tennis match.\n",
    "\n",
    "-   Practicing tennis against a wall.\n",
    "\n",
    "-   Performing a high jump.\n",
    "\n",
    "-   Knitting a sweater.\n",
    "\n",
    "-   Bidding on an item at an auction.\n",
    "\n",
    "**6.)** For each of the following activities, give a PEAS description of the\n",
    "        task environment and characterize it in terms of the properties listed\n",
    "        in .\n",
    "\n",
    "-   Performing a gymnastics floor routine.\n",
    "\n",
    "-   Exploring the subsurface oceans of Titan.\n",
    "\n",
    "-   Playing soccer.\n",
    "\n",
    "-   Shopping for used AI books on the Internet.\n",
    "\n",
    "-   Practicing tennis against a wall.\n",
    "\n",
    "-   Performing a high jump.\n",
    "\n",
    "-   Bidding on an item at an auction.\n",
    "\n",
    "**7.)** Define in your own words the following terms: agent, agent function,\n",
    "        agent program, rationality, autonomy, reflex agent, model-based agent,\n",
    "        goal-based agent, utility-based agent, learning agent.\n",
    "\n",
    "**8.)** This exercise explores the differences between agent functions and agent\n",
    "        programs.\n",
    "\n",
    "1.  Can there be more than one agent program that implements a given\n",
    "    agent function? Give an example, or show why one is not possible.\n",
    "\n",
    "2.  Are there agent functions that cannot be implemented by any agent\n",
    "    program?\n",
    "\n",
    "3.  Given a fixed machine architecture, does each agent program\n",
    "    implement exactly one agent function?\n",
    "\n",
    "4.  Given an architecture with $n$ bits of storage, how many different\n",
    "    possible agent programs are there?\n",
    "\n",
    "5.  Suppose we keep the agent program fixed but speed up the machine by\n",
    "    a factor of two. Does that change the agent function?\n",
    "\n",
    "**9.)** Write pseudocode agent programs for the goal-based and utility-based\n",
    "agents.\n",
    "\n",
    "**10.)** Consider a simple thermostat that turns on a furnace when the\n",
    "         temperature is at least 3 degrees below the setting, and turns off a\n",
    "         furnace when the temperature is at least 3 degrees above the setting. Is\n",
    "         a thermostat an instance of a simple reflex agent, a model-based reflex \n",
    "         agent, or a goal-based agent?\n",
    "\n",
    "**11.)** The following exercises all concern the implementation of environments\n",
    "         and agents for the vacuum-cleaner world.\n",
    "\n",
    "**12.)** Implement a performance-measuring environment simulator for the\n",
    "         vacuum-cleaner world depicted in and specified on . Your implementation\n",
    "         should be modular so that the sensors, actuators, and environment\n",
    "         characteristics (size, shape, dirt placement, etc.) can be changed\n",
    "         easily. (*Note:* for some choices of programming language and\n",
    "         operating system there are already implementations in the online code\n",
    "         repository.)\n",
    "\n",
    "**13.)** Implement a simple reflex agent for the vacuum environment in . Run the\n",
    "         environment with this agent for all possible initial dirt configurations\n",
    "         and agent locations. Record the performance score for each configuration\n",
    "         and the overall average score.\n",
    "\n",
    "**14.)** Consider a modified version of the vacuum environment in , in which the\n",
    "         agent is penalized one point for each movement.\n",
    "\n",
    "1.  Can a simple reflex agent be perfectly rational for this\n",
    "    environment? Explain.\n",
    "\n",
    "2.  What about a reflex agent with state? Design such an agent.\n",
    "\n",
    "3.  How do your answers to **a** and **b** change if the agent’s\n",
    "    percepts give it the clean/dirty status of every square in the\n",
    "    environment?\n",
    "\n",
    "**14.)** Consider a modified version of the vacuum environment in , in which the\n",
    "         geography of the environment—its extent, boundaries, and obstacles—is\n",
    "         unknown, as is the initial dirt configuration. (The agent can go\n",
    "         ${Up}$ and ${Down}$ as well as ${Left}$ and ${Right}$.)\n",
    "\n",
    "1.  Can a simple reflex agent be perfectly rational for this\n",
    "    environment? Explain.\n",
    "\n",
    "2.  Can a simple reflex agent with a ${randomized}$ agent function\n",
    "    outperform a simple reflex agent? Design such an agent and measure\n",
    "    its performance on several environments.\n",
    "\n",
    "3.  Can you design an environment in which your randomized agent will\n",
    "    perform poorly? Show your results.\n",
    "\n",
    "4.  Can a reflex agent with state outperform a simple reflex agent?\n",
    "    Design such an agent and measure its performance on several\n",
    "    environments. Can you design a rational agent of this type?\n",
    "\n",
    "**15.)** Repeat for the case in which the location sensor is replaced with a\n",
    "         “bump” sensor that detects the agent’s attempts to move into an obstacle\n",
    "         or to cross the boundaries of the environment. Suppose the bump sensor\n",
    "         stops working; how should the agent behave?\n",
    "\n",
    "**16.)** The vacuum environments in the preceding exercises have all been\n",
    "         deterministic. Discuss possible agent programs for each of the following\n",
    "         stochastic versions:\n",
    "\n",
    "1.  Murphy’s law: twenty-five percent of the time, the ${Suck}$ action\n",
    "    fails to clean the floor if it is dirty and deposits dirt onto the\n",
    "    floor if the floor is clean. How is your agent program affected if\n",
    "    the dirt sensor gives the wrong answer 10% of the time?\n",
    "\n",
    "2.  Small children: At each time step, each clean square has a 10%\n",
    "    chance of becoming dirty. Can you come up with a rational agent\n",
    "    design for this case?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
